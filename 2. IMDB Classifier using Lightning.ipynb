{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Our Data and Data Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "TEXT = data.Field(tokenize = 'spacy', include_lengths = True, batch_first=True)\n",
    "LABEL = data.LabelField(dtype = torch.float)\n",
    "\n",
    "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)\n",
    "train_data, valid_data = train_data.split(split_ratio=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17500, 25000, 7500)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(test_data), len(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 25_000\n",
    "\n",
    "TEXT.build_vocab(train_data, \n",
    "                 max_size = MAX_VOCAB_SIZE, \n",
    "                 vectors = \"glove.6B.100d\", \n",
    "                 unk_init = torch.Tensor.normal_)\n",
    "\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    sort_within_batch = True,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25002"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TEXT.vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[torchtext.data.batch.Batch of size 64]\n",
       "\t[.text]:('[torch.cuda.LongTensor of size 64x133 (GPU 0)]', '[torch.cuda.LongTensor of size 64 (GPU 0)]')\n",
       "\t[.label]:[torch.cuda.FloatTensor of size 64 (GPU 0)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(train_iterator.__iter__())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.text:\n",
      "(tensor([[  66, 2872,   75,  ...,    4, 5734,   42],\n",
      "        [  66, 4056,   24,  ...,   19, 1697,    4],\n",
      "        [ 314,   31,   81,  ...,    2, 1923,    4],\n",
      "        ...,\n",
      "        [8661,   42,  266,  ...,    1,    1,    1],\n",
      "        [  11,  626,  814,  ...,    1,    1,    1],\n",
      "        [  11,  172,    5,  ...,    1,    1,    1]], device='cuda:0'), tensor([274, 274, 274, 274, 274, 274, 273, 273, 273, 273, 273, 273, 273, 273,\n",
      "        273, 273, 273, 273, 273, 272, 272, 272, 272, 272, 272, 272, 272, 272,\n",
      "        272, 272, 272, 272, 271, 271, 271, 271, 271, 271, 271, 271, 271, 271,\n",
      "        271, 271, 271, 271, 271, 271, 271, 271, 270, 270, 270, 270, 270, 270,\n",
      "        270, 270, 270, 270, 270, 270, 270, 270], device='cuda:0'))\n",
      "batch.label:\n",
      "tensor([1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 1., 0., 0., 1., 0., 1., 1., 0.], device='cuda:0') 64\n"
     ]
    }
   ],
   "source": [
    "for batch in train_iterator:\n",
    "    print(\"batch.text:\")\n",
    "    print(batch.text)\n",
    "    print(\"batch.label:\")\n",
    "    print(batch.label, len(batch.label))\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Lightning Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(pl.LightningModule):\n",
    "    def __init__(self, vocab_size=25002, embedding_dim=100, hidden_dim=256, output_dim=1, n_layers=2, \n",
    "                 bidirectional=True, dropout=0.5, pad_idx=1):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx) #25002, 100, 1\n",
    "        \n",
    "        self.rnn = nn.LSTM(embedding_dim, \n",
    "                           hidden_dim, \n",
    "                           num_layers=n_layers, \n",
    "                           bidirectional=bidirectional, \n",
    "                           dropout=dropout, batch_first=True)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim) #512, 1\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout) #0.5\n",
    "        \n",
    "    def forward(self, text, text_lengths):\n",
    "        #1. feed text into embedding with dropouts\n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "        #embedded = [batch size(64), sent len(x), emb dim(100)]\n",
    "\n",
    "        #2. pack sequence\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths,batch_first=True)\n",
    "        \n",
    "        #3. feed into LSTM\n",
    "        packed_output, (hidden, cell) = self.rnn(packed_embedded)\n",
    "        \n",
    "        #4. unpack sequence\n",
    "        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output,batch_first=True)\n",
    "       \n",
    "        #5. Concat final forward hidden state and backward state value\n",
    "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
    "            \n",
    "        return self.fc(hidden)\n",
    "\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return train_iterator\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return valid_iterator\n",
    "\n",
    "    def binary_accuracy(self,preds, y):\n",
    "        \"\"\"\n",
    "        Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "        \"\"\"\n",
    "\n",
    "        #round predictions to the closest integer\n",
    "        rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "        correct = (rounded_preds == y).float() #convert into float for division \n",
    "        acc = correct.sum() / len(correct)\n",
    "        return acc\n",
    "    \n",
    "    def loss_function(self, predictions, labels):\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        loss = criterion(predictions, labels)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return Adam(self.parameters())\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        text, text_lengths = batch.text\n",
    "        \n",
    "        predictions = model(text, text_lengths).squeeze(1)\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "        loss = criterion(predictions, batch.label)\n",
    "        \n",
    "        acc = self.binary_accuracy(predictions, batch.label)\n",
    "        \n",
    "        output = {\n",
    "            'loss': loss, # required\n",
    "            'progress_bar': {'acc':acc}, # Optional, must be tensor\n",
    "            'train_acc':acc\n",
    "        }\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def training_epoch_end(self, outputs):\n",
    "        epoch_acc = 0\n",
    "        for loss in outputs:\n",
    "            epoch_acc += loss['train_acc']\n",
    "        epoch_acc /= len(outputs)\n",
    "        \n",
    "      \n",
    "        results = {\n",
    "        'log': {'train_epoch_acc': epoch_acc}\n",
    "        }\n",
    "        return results\n",
    "        \n",
    "        \n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        text, text_lengths = batch.text\n",
    "\n",
    "        predictions = model(text, text_lengths).squeeze(1)\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "        loss = criterion(predictions, batch.label)\n",
    "\n",
    "        acc = self.binary_accuracy(predictions, batch.label)\n",
    "        return {\n",
    "            'loss':loss,\n",
    "            'val_acc':acc\n",
    "        }\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        epoch_loss = 0\n",
    "        epoch_acc = 0\n",
    "        for loss in outputs:\n",
    "            epoch_acc += loss['val_acc']\n",
    "        epoch_acc /= len(outputs)\n",
    "        \n",
    "        for loss in outputs:\n",
    "            epoch_loss += loss['loss']   \n",
    "        epoch_loss /= len(outputs)\n",
    "        \n",
    "\n",
    "        \n",
    "        # Show this data into progress bar\n",
    "        tqdm_dict = {'val_epoch_acc': epoch_acc, 'val_epoch_loss':epoch_loss}\n",
    "\n",
    "        results = {\n",
    "        'progress_bar': tqdm_dict,\n",
    "        'log': {'val_acc': epoch_acc}\n",
    "        }\n",
    "        return results\n",
    "\n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Lightning Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early stop call back\n",
    "Stop training when a monitored quantity has stopped improving. By default trainer will run for 1000 epochs.\n",
    "\n",
    "**Parameters:**\n",
    "* monitor (str): quantity to be monitored. Default: ‘val_loss’.\n",
    "* min_delta (float) – minimum change in the monitored quantity to qualify as an improvement, i.e. an absolute change of less than min_delta, will count as no improvement. Default: 0.\n",
    "* patience (int) – number of epochs with no improvement after which training will be stopped. Default: 0.\n",
    "* verbose (bool) – verbosity mode. Default: False.\n",
    "* mode (str) – one of {auto, min, max}. In min mode, training will stop when the quantity monitored has stopped decreasing; in max mode it will stop when the quantity monitored has stopped increasing; in auto mode, the direction is automatically inferred from the name of the monitored quantity. Default: ‘auto’.\n",
    "* strict (bool) – whether to crash the training if monitor is not found in the metrics. Default: True.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_epoch_acc', \n",
    "                              min_delta=0.001,\n",
    "                              patience=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Checkpoint\n",
    "Automatically save model checkpoints during training.\n",
    "\n",
    "**Parameters:**\n",
    "* filepath (Optional[str]) –path to save the model file. Can contain named formatting options to be auto-filled.\n",
    "* monitor (str) – quantity to monitor.\n",
    "* verbose (bool) – verbosity mode. Default: False.\n",
    "* save_top_k (int) – if save_top_k == k, the best k models according to the quantity monitored will be saved. if save_top_k == 0, no models are saved. if save_top_k == -1, all models are saved. Please note that the monitors are checked every period epochs. if save_top_k >= 2 and the callback is called multiple times inside an epoch, the name of the saved file will be appended with a version count starting with v0.\n",
    "* mode (str) – one of {auto, min, max}. If save_top_k != 0, the decision to overwrite the current save file is made based on either the maximization or the minimization of the monitored quantity. For val_acc, this should be max, for val_loss this should be min, etc. In auto mode, the direction is automatically inferred from the name of the monitored quantity.\n",
    "* save_weights_only (bool) – if True, then only the model’s weights will be saved (model.save_weights(filepath)), else the full model is saved (model.save(filepath)).\n",
    "* period (int) – Interval (number of epochs) between checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath='./saved_models/_{epoch:02d}-{val_epoch_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    verbose=True,\n",
    "    monitor='val_epoch_acc',\n",
    "    mode='max',\n",
    "    prefix=''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/av6101604/env/lib64/python3.6/site-packages/pytorch_lightning/loggers/tensorboard.py:106: UserWarning: Hyperparameter logging is not available for Torch version 1.2.0. Skipping log_hyperparams. Upgrade to Torch 1.3.0 or above to enable hyperparameter logging.\n",
      "  f\"Hyperparameter logging is not available for Torch version {torch.__version__}.\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validation sanity check', layout=Layout(flex='2'), max=5.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f94f612f86254686b590dd213a2db2ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=1.0), HTML(value='')), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/av6101604/env/lib64/python3.6/site-packages/pytorch_lightning/utilities/warnings.py:18: RuntimeWarning: Displayed epoch numbers in the progress bar start from \"1\" until v0.6.x, but will start from \"0\" in v0.8.0.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=118.0, style=Pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=118.0, style=Pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=118.0, style=Pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=118.0, style=Pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=118.0, style=Pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=118.0, style=Pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=118.0, style=Pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=118.0, style=Pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=118.0, style=Pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=118.0, style=Pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=118.0, style=Pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=118.0, style=Pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=118.0, style=Pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=118.0, style=Pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=118.0, style=Pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_DIM = len(TEXT.vocab) #25002\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.5\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "model = RNN(INPUT_DIM, \n",
    "            EMBEDDING_DIM, \n",
    "            HIDDEN_DIM, \n",
    "            OUTPUT_DIM, \n",
    "            N_LAYERS, \n",
    "            BIDIRECTIONAL, \n",
    "            DROPOUT, \n",
    "            PAD_IDX)\n",
    "\n",
    "trainer = Trainer(gpus=1,early_stop_callback=early_stopping,checkpoint_callback=checkpoint_callback)#max_epochs=4)\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual loading model from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model = model.load_from_checkpoint(checkpoint_path=\"./saved_models/_epoch=12-val_epoch_acc=0.90.ckpt\")\n",
    "#OR\n",
    "checkpoint = torch.load(\"./saved_models/_epoch=12-val_epoch_acc=0.90.ckpt\", map_location=lambda storage, loc: storage)\n",
    "model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restore Training State for trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(resume_from_checkpoint='./saved_models/_epoch=12-val_epoch_acc=0.90.ckpt')\n",
    "\n",
    "# automatically restores model, epoch, step, LR schedulers, apex, etc...\n",
    "#trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "def predict_sentiment(model, sentence):\n",
    "    model.eval()\n",
    "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
    "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
    "    length = [len(indexed)]\n",
    "    tensor = torch.LongTensor(indexed).to(device)\n",
    "    tensor = tensor.unsqueeze(0)\n",
    "    length_tensor = torch.LongTensor(length)\n",
    "    prediction = torch.sigmoid(model(tensor, length_tensor))\n",
    "    return prediction.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000628557289019227"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(model, \"This film is terrible\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9993434548377991"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(model, \"This film is awesome! I love it.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
